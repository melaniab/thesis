{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative, content-based and hybrid filtering for GoodReads dataset.\n",
    "\n",
    "Ideas from https://github.com/jfkirk/tensorrec/blob/master/examples/getting_started.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorrec\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "#TODO: check for the random seed\n",
    "import tensorflow as tf \n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the experiments \n",
    "N_BOOKS = 2000\n",
    "EMBEDDING_DIMENTIONS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative filtering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ratings\n"
     ]
    }
   ],
   "source": [
    "print('Loading ratings')\n",
    "with open('data/ratings_reduced.csv', 'r') as ratings_file:\n",
    "    ratings_file_reader = csv.reader(ratings_file, delimiter=' ')\n",
    "    raw_ratings = list(ratings_file_reader)\n",
    "# raw_ratings_header = raw_ratings.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['35040', '1', '5'],\n",
       " ['34489', '1', '4'],\n",
       " ['33191', '1', '5'],\n",
       " ['27976', '1', '5'],\n",
       " ['28689', '1', '4'],\n",
       " ['9517', '1', '4'],\n",
       " ['52256', '1', '5'],\n",
       " ['653', '1', '3'],\n",
       " ['37909', '1', '5'],\n",
       " ['21092', '1', '4'],\n",
       " ['42879', '1', '4'],\n",
       " ['17991', '1', '5'],\n",
       " ['14565', '1', '4'],\n",
       " ['14255', '1', '4'],\n",
       " ['20455', '1', '5'],\n",
       " ['3623', '1', '5'],\n",
       " ['12438', '1', '5'],\n",
       " ['19923', '1', '5'],\n",
       " ['4389', '1', '4'],\n",
       " ['27164', '1', '5'],\n",
       " ['25957', '1', '5'],\n",
       " ['27457', '1', '5'],\n",
       " ['46416', '1', '5'],\n",
       " ['43625', '1', '4'],\n",
       " ['44635', '1', '4'],\n",
       " ['3572', '1', '5'],\n",
       " ['41222', '1', '5'],\n",
       " ['51468', '1', '4'],\n",
       " ['12926', '1', '5'],\n",
       " ['5509', '1', '4'],\n",
       " ['3886', '1', '5'],\n",
       " ['4789', '1', '4'],\n",
       " ['23286', '1', '4'],\n",
       " ['13590', '1', '5'],\n",
       " ['6272', '1', '5'],\n",
       " ['42672', '1', '4'],\n",
       " ['33627', '1', '5'],\n",
       " ['47426', '1', '5'],\n",
       " ['2736', '1', '4'],\n",
       " ['19534', '1', '5'],\n",
       " ['488', '1', '4'],\n",
       " ['21594', '1', '5'],\n",
       " ['3022', '1', '4'],\n",
       " ['45419', '1', '5'],\n",
       " ['10536', '1', '5'],\n",
       " ['32232', '1', '5'],\n",
       " ['12531', '1', '4'],\n",
       " ['46011', '1', '5'],\n",
       " ['46324', '1', '5'],\n",
       " ['1137', '1', '3'],\n",
       " ['52411', '1', '5'],\n",
       " ['17031', '1', '5'],\n",
       " ['5646', '1', '5'],\n",
       " ['29907', '1', '5'],\n",
       " ['41800', '1', '5'],\n",
       " ['39310', '1', '4'],\n",
       " ['20878', '1', '4'],\n",
       " ['5912', '1', '5'],\n",
       " ['42177', '1', '5'],\n",
       " ['18989', '1', '5'],\n",
       " ['3597', '1', '5'],\n",
       " ['6539', '1', '3'],\n",
       " ['32088', '1', '5'],\n",
       " ['37565', '1', '3'],\n",
       " ['23364', '1', '4'],\n",
       " ['9536', '1', '5'],\n",
       " ['37613', '1', '5'],\n",
       " ['49578', '1', '5'],\n",
       " ['9802', '1', '5'],\n",
       " ['4193', '1', '5'],\n",
       " ['27860', '1', '3'],\n",
       " ['3082', '1', '5'],\n",
       " ['6633', '1', '4'],\n",
       " ['42213', '1', '5'],\n",
       " ['48931', '1', '3'],\n",
       " ['32431', '1', '4'],\n",
       " ['42590', '1', '5'],\n",
       " ['40931', '1', '4'],\n",
       " ['32295', '1', '3'],\n",
       " ['17123', '1', '5'],\n",
       " ['25196', '1', '4'],\n",
       " ['22468', '1', '5'],\n",
       " ['40818', '1', '5'],\n",
       " ['8195', '1', '5'],\n",
       " ['44566', '1', '5'],\n",
       " ['45732', '1', '5'],\n",
       " ['3595', '1', '4'],\n",
       " ['30780', '1', '4'],\n",
       " ['45945', '1', '5'],\n",
       " ['31228', '1', '5'],\n",
       " ['3180', '1', '5'],\n",
       " ['12100', '1', '4'],\n",
       " ['2277', '1', '4'],\n",
       " ['21873', '1', '4'],\n",
       " ['13134', '1', '5'],\n",
       " ['14476', '1', '5'],\n",
       " ['10270', '1', '5'],\n",
       " ['14575', '1', '5'],\n",
       " ['43305', '1', '3'],\n",
       " ['29776', '1', '5'],\n",
       " ['28277', '1', '5'],\n",
       " ['10274', '1', '4'],\n",
       " ['21603', '1', '4'],\n",
       " ['49988', '1', '5'],\n",
       " ['26015', '1', '5'],\n",
       " ['20629', '1', '1'],\n",
       " ['13244', '1', '3'],\n",
       " ['9880', '1', '5'],\n",
       " ['15637', '1', '5'],\n",
       " ['38019', '1', '4'],\n",
       " ['45282', '1', '4'],\n",
       " ['5184', '1', '5'],\n",
       " ['22489', '1', '4'],\n",
       " ['26951', '1', '5'],\n",
       " ['12092', '1', '4'],\n",
       " ['21460', '1', '5'],\n",
       " ['36712', '1', '4'],\n",
       " ['1483', '1', '5'],\n",
       " ['48654', '1', '5'],\n",
       " ['17535', '1', '5'],\n",
       " ['39366', '1', '3'],\n",
       " ['13464', '1', '5'],\n",
       " ['34008', '1', '4'],\n",
       " ['3064', '1', '5'],\n",
       " ['4752', '1', '5'],\n",
       " ['11457', '1', '4'],\n",
       " ['30993', '1', '5'],\n",
       " ['34718', '1', '3'],\n",
       " ['25835', '1', '5'],\n",
       " ['13154', '1', '5'],\n",
       " ['18523', '1', '3'],\n",
       " ['47089', '1', '4'],\n",
       " ['51628', '1', '5'],\n",
       " ['29566', '1', '5'],\n",
       " ['22339', '1', '4'],\n",
       " ['52638', '1', '5'],\n",
       " ['48219', '1', '5'],\n",
       " ['15251', '1', '4'],\n",
       " ['44379', '1', '5'],\n",
       " ['41527', '1', '5'],\n",
       " ['38351', '1', '5'],\n",
       " ['27610', '1', '4'],\n",
       " ['16392', '1', '5'],\n",
       " ['20763', '1', '5'],\n",
       " ['46128', '1', '5'],\n",
       " ['30220', '1', '4'],\n",
       " ['20354', '1', '3'],\n",
       " ['53192', '1', '5'],\n",
       " ['2257', '1', '5'],\n",
       " ['52057', '1', '4'],\n",
       " ['29750', '1', '5'],\n",
       " ['13703', '1', '5'],\n",
       " ['5227', '1', '5'],\n",
       " ['12561', '1', '4'],\n",
       " ['25581', '1', '3'],\n",
       " ['40711', '1', '5'],\n",
       " ['3758', '1', '5'],\n",
       " ['13287', '1', '5'],\n",
       " ['15329', '1', '5'],\n",
       " ['52848', '1', '5'],\n",
       " ['4504', '1', '5'],\n",
       " ['13502', '1', '5'],\n",
       " ['11229', '1', '3'],\n",
       " ['26785', '1', '5'],\n",
       " ['137', '1', '4'],\n",
       " ['49371', '1', '5'],\n",
       " ['53036', '1', '5'],\n",
       " ['503', '1', '5'],\n",
       " ['40458', '1', '3'],\n",
       " ['28501', '1', '5'],\n",
       " ['2988', '1', '5'],\n",
       " ['223', '1', '3'],\n",
       " ['21998', '1', '5'],\n",
       " ['43566', '1', '5'],\n",
       " ['33844', '1', '4'],\n",
       " ['37396', '1', '5'],\n",
       " ['24518', '1', '5'],\n",
       " ['6178', '1', '5'],\n",
       " ['9122', '1', '5'],\n",
       " ['3054', '1', '5'],\n",
       " ['45749', '1', '4'],\n",
       " ['29823', '1', '4'],\n",
       " ['47580', '1', '5'],\n",
       " ['9386', '1', '4'],\n",
       " ['35657', '1', '4'],\n",
       " ['16339', '1', '5'],\n",
       " ['20334', '1', '3'],\n",
       " ['17164', '1', '5'],\n",
       " ['42342', '1', '5'],\n",
       " ['46430', '1', '4'],\n",
       " ['2288', '1', '4'],\n",
       " ['9026', '1', '3'],\n",
       " ['50253', '1', '5'],\n",
       " ['3603', '1', '5'],\n",
       " ['22163', '1', '5'],\n",
       " ['23458', '1', '5'],\n",
       " ['11108', '1', '4'],\n",
       " ['2418', '1', '5'],\n",
       " ['15337', '1', '3'],\n",
       " ['18104', '1', '5'],\n",
       " ['22485', '1', '5'],\n",
       " ['39589', '1', '5'],\n",
       " ['12414', '1', '2'],\n",
       " ['40884', '1', '4'],\n",
       " ['29854', '1', '3'],\n",
       " ['4633', '1', '5'],\n",
       " ['5279', '1', '4'],\n",
       " ['6446', '1', '3'],\n",
       " ['40348', '1', '5'],\n",
       " ['48142', '1', '4'],\n",
       " ['8258', '1', '4'],\n",
       " ['41885', '1', '4'],\n",
       " ['29055', '1', '4'],\n",
       " ['7214', '1', '5'],\n",
       " ['46996', '1', '4'],\n",
       " ['5144', '1', '5'],\n",
       " ['30924', '1', '4'],\n",
       " ['29695', '1', '5'],\n",
       " ['248', '1', '5'],\n",
       " ['28551', '1', '4'],\n",
       " ['13882', '1', '5'],\n",
       " ['26309', '1', '5'],\n",
       " ['15880', '1', '5'],\n",
       " ['394', '1', '5'],\n",
       " ['43910', '1', '5'],\n",
       " ['5161', '1', '3'],\n",
       " ['31041', '1', '2'],\n",
       " ['10809', '1', '5'],\n",
       " ['23451', '1', '5'],\n",
       " ['14478', '1', '5'],\n",
       " ['8219', '1', '4'],\n",
       " ['27800', '1', '4'],\n",
       " ['4105', '1', '4'],\n",
       " ['29137', '1', '5'],\n",
       " ['31763', '1', '5'],\n",
       " ['17740', '1', '5'],\n",
       " ['42266', '1', '5'],\n",
       " ['34028', '1', '5'],\n",
       " ['50444', '1', '5'],\n",
       " ['44349', '1', '5'],\n",
       " ['28051', '1', '5'],\n",
       " ['15790', '1', '5'],\n",
       " ['22866', '1', '5'],\n",
       " ['9864', '1', '5'],\n",
       " ['2937', '1', '5'],\n",
       " ['20172', '1', '5'],\n",
       " ['52593', '1', '5'],\n",
       " ['23908', '1', '5'],\n",
       " ['52047', '1', '5'],\n",
       " ['30315', '1', '5'],\n",
       " ['21520', '1', '5'],\n",
       " ['16213', '1', '5'],\n",
       " ['34336', '1', '4'],\n",
       " ['44665', '1', '3'],\n",
       " ['4372', '1', '4'],\n",
       " ['45564', '1', '5'],\n",
       " ['45162', '1', '4'],\n",
       " ['12846', '1', '4'],\n",
       " ['43396', '1', '4'],\n",
       " ['5911', '1', '4'],\n",
       " ['33371', '1', '4'],\n",
       " ['15764', '1', '5'],\n",
       " ['29033', '1', '5'],\n",
       " ['18456', '1', '4'],\n",
       " ['17541', '1', '5'],\n",
       " ['11212', '1', '5'],\n",
       " ['10866', '1', '4'],\n",
       " ['9780', '1', '4'],\n",
       " ['51834', '1', '5'],\n",
       " ['647', '1', '3'],\n",
       " ['45925', '1', '5'],\n",
       " ['13517', '1', '4'],\n",
       " ['12558', '1', '4'],\n",
       " ['25888', '1', '3'],\n",
       " ['5884', '1', '5'],\n",
       " ['36433', '1', '5'],\n",
       " ['7811', '1', '4'],\n",
       " ['39192', '1', '5'],\n",
       " ['52844', '1', '4'],\n",
       " ['32701', '1', '4'],\n",
       " ['18246', '1', '4'],\n",
       " ['47716', '1', '5'],\n",
       " ['46033', '1', '5'],\n",
       " ['52795', '1', '4'],\n",
       " ['47096', '1', '5'],\n",
       " ['34480', '1', '5'],\n",
       " ['34197', '1', '5'],\n",
       " ['51500', '1', '3'],\n",
       " ['3747', '1', '3'],\n",
       " ['3601', '1', '5'],\n",
       " ['46237', '1', '3'],\n",
       " ['21028', '1', '3'],\n",
       " ['20016', '1', '4'],\n",
       " ['25017', '1', '5'],\n",
       " ['44951', '1', '5'],\n",
       " ['6295', '1', '5'],\n",
       " ['12118', '1', '5'],\n",
       " ['2279', '1', '4'],\n",
       " ['41125', '1', '4'],\n",
       " ['12696', '1', '5'],\n",
       " ['51105', '1', '5'],\n",
       " ['36645', '1', '5'],\n",
       " ['45937', '1', '5'],\n",
       " ['39793', '1', '5'],\n",
       " ['20997', '1', '5'],\n",
       " ['1180', '1', '5'],\n",
       " ['29523', '1', '3'],\n",
       " ['50294', '1', '4'],\n",
       " ['11630', '1', '5'],\n",
       " ['51510', '1', '5'],\n",
       " ['23435', '1', '5'],\n",
       " ['33503', '1', '5'],\n",
       " ['40521', '1', '5'],\n",
       " ['50774', '1', '5'],\n",
       " ['28132', '1', '5'],\n",
       " ['50251', '1', '5'],\n",
       " ['47753', '1', '5'],\n",
       " ['34420', '1', '5'],\n",
       " ['50621', '1', '5'],\n",
       " ['20773', '1', '5'],\n",
       " ['41017', '1', '3'],\n",
       " ['49653', '1', '5'],\n",
       " ['32375', '1', '5'],\n",
       " ['12977', '1', '4'],\n",
       " ['8236', '1', '5'],\n",
       " ['31750', '1', '3'],\n",
       " ['2322', '1', '4'],\n",
       " ['41543', '1', '4'],\n",
       " ['46226', '1', '5'],\n",
       " ['27145', '1', '5'],\n",
       " ['40507', '1', '5'],\n",
       " ['29307', '1', '4'],\n",
       " ['16761', '1', '5'],\n",
       " ['13120', '1', '4'],\n",
       " ['20135', '1', '4'],\n",
       " ['15115', '1', '4'],\n",
       " ['12930', '1', '5'],\n",
       " ['16307', '1', '5'],\n",
       " ['40225', '1', '5'],\n",
       " ['20534', '1', '5'],\n",
       " ['36247', '1', '5'],\n",
       " ['31940', '1', '3'],\n",
       " ['35236', '1', '4'],\n",
       " ['7475', '1', '5'],\n",
       " ['41875', '1', '5'],\n",
       " ['15113', '1', '4'],\n",
       " ['36409', '1', '3'],\n",
       " ['20162', '1', '5'],\n",
       " ['10363', '1', '5'],\n",
       " ['39010', '1', '5'],\n",
       " ['46225', '1', '5'],\n",
       " ['32740', '1', '4'],\n",
       " ['2069', '1', '5'],\n",
       " ['33688', '1', '4'],\n",
       " ['10389', '1', '5'],\n",
       " ['13476', '1', '4'],\n",
       " ['47188', '1', '5'],\n",
       " ['47657', '1', '5'],\n",
       " ['1350', '1', '4'],\n",
       " ['32612', '1', '5'],\n",
       " ['1728', '1', '5'],\n",
       " ['37682', '1', '5'],\n",
       " ['21551', '1', '4'],\n",
       " ['48806', '1', '5'],\n",
       " ['11670', '1', '3'],\n",
       " ['1284', '1', '4'],\n",
       " ['50735', '1', '5'],\n",
       " ['1390', '1', '5'],\n",
       " ['21831', '1', '3'],\n",
       " ['32098', '1', '5'],\n",
       " ['44689', '1', '5'],\n",
       " ['36921', '1', '5'],\n",
       " ['50008', '1', '5'],\n",
       " ['25759', '1', '5'],\n",
       " ['15891', '1', '5'],\n",
       " ['42287', '1', '5'],\n",
       " ['49748', '1', '5'],\n",
       " ['14993', '1', '5'],\n",
       " ['25580', '1', '5'],\n",
       " ['34387', '1', '4'],\n",
       " ['5636', '1', '5'],\n",
       " ['7587', '1', '5'],\n",
       " ['3705', '1', '3'],\n",
       " ['28702', '1', '3'],\n",
       " ['19715', '1', '5'],\n",
       " ['14903', '1', '4'],\n",
       " ['19258', '1', '3'],\n",
       " ['46477', '1', '5'],\n",
       " ['49244', '1', '5'],\n",
       " ['7266', '1', '5'],\n",
       " ['46034', '1', '5'],\n",
       " ['8550', '1', '4'],\n",
       " ['21180', '1', '4'],\n",
       " ['36895', '1', '5'],\n",
       " ['28492', '1', '5'],\n",
       " ['1286', '1', '4'],\n",
       " ['210', '1', '3'],\n",
       " ['32733', '1', '3'],\n",
       " ['44134', '1', '3'],\n",
       " ['53407', '1', '2'],\n",
       " ['6478', '1', '2'],\n",
       " ['9029', '1', '5'],\n",
       " ['203', '1', '4'],\n",
       " ['10675', '1', '5'],\n",
       " ['44304', '1', '5'],\n",
       " ['40922', '1', '4'],\n",
       " ['3605', '1', '5'],\n",
       " ['11477', '1', '5'],\n",
       " ['7834', '1', '4'],\n",
       " ['48399', '1', '5'],\n",
       " ['38524', '1', '5'],\n",
       " ['23828', '1', '5'],\n",
       " ['51970', '1', '5'],\n",
       " ['23270', '1', '5'],\n",
       " ['5248', '1', '2'],\n",
       " ['52728', '1', '5'],\n",
       " ['15784', '1', '3'],\n",
       " ['6286', '1', '5'],\n",
       " ['39185', '1', '5'],\n",
       " ['18329', '1', '5'],\n",
       " ['2900', '1', '5'],\n",
       " ['3046', '1', '3'],\n",
       " ['40539', '1', '5'],\n",
       " ['5804', '1', '4'],\n",
       " ['49622', '1', '4'],\n",
       " ['39341', '1', '5'],\n",
       " ['11544', '1', '3'],\n",
       " ['25715', '1', '5'],\n",
       " ['19966', '1', '5'],\n",
       " ['2846', '1', '4'],\n",
       " ['3844', '1', '5'],\n",
       " ['37333', '1', '4'],\n",
       " ['6609', '1', '5'],\n",
       " ['4537', '1', '4'],\n",
       " ['25464', '1', '4'],\n",
       " ['39166', '1', '4'],\n",
       " ['51052', '1', '4'],\n",
       " ['50320', '1', '5'],\n",
       " ['21965', '1', '5'],\n",
       " ['3297', '1', '5'],\n",
       " ['48550', '1', '5'],\n",
       " ['24383', '1', '5'],\n",
       " ['27940', '1', '5'],\n",
       " ['4791', '1', '5'],\n",
       " ['5112', '1', '4'],\n",
       " ['21524', '1', '5'],\n",
       " ['1115', '1', '4'],\n",
       " ['16642', '1', '3'],\n",
       " ['42463', '1', '4'],\n",
       " ['16354', '1', '5'],\n",
       " ['18637', '1', '5'],\n",
       " ['6228', '1', '4'],\n",
       " ['29419', '1', '5'],\n",
       " ['15596', '1', '5'],\n",
       " ['12232', '1', '4'],\n",
       " ['5637', '1', '5'],\n",
       " ['6235', '1', '5'],\n",
       " ['46645', '1', '5'],\n",
       " ['20936', '1', '4'],\n",
       " ['46538', '1', '4'],\n",
       " ['35763', '1', '5'],\n",
       " ['46636', '1', '4'],\n",
       " ['23067', '1', '5'],\n",
       " ['29371', '1', '3'],\n",
       " ['163', '1', '5'],\n",
       " ['2831', '1', '5'],\n",
       " ['19604', '1', '5'],\n",
       " ['11262', '1', '5'],\n",
       " ['11891', '1', '3'],\n",
       " ['21780', '1', '3'],\n",
       " ['27260', '1', '5'],\n",
       " ['18419', '1', '5'],\n",
       " ['2044', '1', '5'],\n",
       " ['38067', '1', '5'],\n",
       " ['19883', '1', '3'],\n",
       " ['28233', '1', '5'],\n",
       " ['36281', '1', '5'],\n",
       " ['9257', '1', '4'],\n",
       " ['3420', '1', '5'],\n",
       " ['18977', '1', '3'],\n",
       " ['9051', '1', '5'],\n",
       " ['47115', '1', '5'],\n",
       " ['11506', '1', '3'],\n",
       " ['31321', '1', '3'],\n",
       " ['4352', '1', '3'],\n",
       " ['12039', '1', '5'],\n",
       " ['46437', '1', '5'],\n",
       " ['43713', '1', '4'],\n",
       " ['4511', '1', '5'],\n",
       " ['952', '1', '4'],\n",
       " ['22875', '1', '3'],\n",
       " ['5496', '1', '3'],\n",
       " ['8058', '1', '5'],\n",
       " ['38334', '1', '3'],\n",
       " ['8736', '1', '4'],\n",
       " ['38479', '1', '5'],\n",
       " ['36441', '1', '5'],\n",
       " ['413', '1', '4'],\n",
       " ['8085', '1', '5'],\n",
       " ['50998', '1', '2'],\n",
       " ['15223', '1', '5'],\n",
       " ['12949', '1', '4'],\n",
       " ['5976', '1', '4'],\n",
       " ['12725', '1', '4'],\n",
       " ['36580', '1', '4'],\n",
       " ['45486', '1', '5'],\n",
       " ['9679', '1', '5'],\n",
       " ['21009', '1', '5'],\n",
       " ['362', '1', '4'],\n",
       " ['10278', '1', '4'],\n",
       " ['38297', '1', '5'],\n",
       " ['10565', '1', '5'],\n",
       " ['47203', '1', '5'],\n",
       " ['23192', '1', '5'],\n",
       " ['7591', '1', '3'],\n",
       " ['10048', '1', '3'],\n",
       " ['15698', '1', '3'],\n",
       " ['33892', '1', '4'],\n",
       " ['37197', '1', '3'],\n",
       " ['6230', '1', '5'],\n",
       " ['13815', '1', '5'],\n",
       " ['9199', '1', '5'],\n",
       " ['40158', '1', '4'],\n",
       " ['32266', '1', '5'],\n",
       " ['47695', '1', '5'],\n",
       " ['36534', '1', '4'],\n",
       " ['16601', '1', '4'],\n",
       " ['38213', '1', '5'],\n",
       " ['47593', '1', '5'],\n",
       " ['24945', '1', '4'],\n",
       " ['44369', '1', '5'],\n",
       " ['6187', '1', '4'],\n",
       " ['30569', '1', '5'],\n",
       " ['30353', '1', '4'],\n",
       " ['42091', '1', '5'],\n",
       " ['30769', '1', '5'],\n",
       " ['45320', '1', '4'],\n",
       " ['20588', '1', '2'],\n",
       " ['49728', '1', '5'],\n",
       " ['13857', '1', '4'],\n",
       " ['1828', '1', '4'],\n",
       " ['25798', '1', '4'],\n",
       " ['21756', '1', '5'],\n",
       " ['25158', '1', '5'],\n",
       " ['5387', '1', '5'],\n",
       " ['51985', '1', '5'],\n",
       " ['8572', '1', '5'],\n",
       " ['9675', '1', '4'],\n",
       " ['22656', '1', '5'],\n",
       " ['11073', '1', '5'],\n",
       " ['7172', '1', '5'],\n",
       " ['15231', '1', '4'],\n",
       " ['16260', '1', '5'],\n",
       " ['44258', '1', '5'],\n",
       " ['25312', '1', '4'],\n",
       " ['15162', '1', '4'],\n",
       " ['9060', '1', '5'],\n",
       " ['28652', '1', '2'],\n",
       " ['43077', '1', '4'],\n",
       " ['1125', '1', '4'],\n",
       " ['50575', '1', '5'],\n",
       " ['30887', '1', '4'],\n",
       " ['47477', '1', '4'],\n",
       " ['21330', '1', '4'],\n",
       " ['51324', '1', '5'],\n",
       " ['40284', '1', '4'],\n",
       " ['23477', '1', '5'],\n",
       " ['26302', '1', '5'],\n",
       " ['31508', '1', '5'],\n",
       " ['34141', '1', '5'],\n",
       " ['14027', '1', '5'],\n",
       " ['22257', '1', '5'],\n",
       " ['13979', '1', '5'],\n",
       " ['5785', '1', '4'],\n",
       " ['48664', '1', '5'],\n",
       " ['14296', '1', '5'],\n",
       " ['14172', '1', '4'],\n",
       " ['32714', '1', '3'],\n",
       " ['14714', '1', '5'],\n",
       " ['27038', '1', '3'],\n",
       " ['16485', '1', '4'],\n",
       " ['959', '1', '4'],\n",
       " ['12040', '1', '5'],\n",
       " ['29078', '1', '5'],\n",
       " ['22066', '1', '5'],\n",
       " ['45677', '1', '5'],\n",
       " ['12657', '1', '4'],\n",
       " ['1357', '1', '5'],\n",
       " ['12440', '1', '5'],\n",
       " ['46755', '1', '4'],\n",
       " ['29871', '1', '5'],\n",
       " ['228', '1', '4'],\n",
       " ['44590', '1', '5'],\n",
       " ['9995', '1', '5'],\n",
       " ['51582', '1', '5'],\n",
       " ['35934', '1', '4'],\n",
       " ['35217', '1', '4'],\n",
       " ['20545', '1', '4'],\n",
       " ['32057', '1', '5'],\n",
       " ['37335', '1', '4'],\n",
       " ['2422', '1', '5'],\n",
       " ['21059', '1', '5'],\n",
       " ['32626', '1', '5'],\n",
       " ['52280', '1', '5'],\n",
       " ['20880', '1', '5'],\n",
       " ['8083', '1', '5'],\n",
       " ['38712', '1', '4'],\n",
       " ['11274', '1', '5'],\n",
       " ['24722', '1', '5'],\n",
       " ['49634', '1', '5'],\n",
       " ['29151', '1', '5'],\n",
       " ['25340', '1', '4'],\n",
       " ['2031', '1', '4'],\n",
       " ['28347', '1', '5'],\n",
       " ['16954', '1', '4'],\n",
       " ['13282', '1', '5'],\n",
       " ['50214', '1', '5'],\n",
       " ['45930', '1', '3'],\n",
       " ['18653', '1', '3'],\n",
       " ['6528', '1', '5'],\n",
       " ['22735', '1', '5'],\n",
       " ['34856', '1', '5'],\n",
       " ['20204', '1', '3'],\n",
       " ['30183', '1', '3'],\n",
       " ['51728', '1', '5'],\n",
       " ['42498', '1', '5'],\n",
       " ['45369', '1', '4'],\n",
       " ['37702', '1', '4'],\n",
       " ['50491', '1', '5'],\n",
       " ['9405', '1', '4'],\n",
       " ['8719', '1', '5'],\n",
       " ['44120', '1', '5'],\n",
       " ['11648', '1', '5'],\n",
       " ['41881', '1', '5'],\n",
       " ['3068', '1', '5'],\n",
       " ['24717', '1', '5'],\n",
       " ['19075', '1', '5'],\n",
       " ['47814', '1', '4'],\n",
       " ['19935', '1', '4'],\n",
       " ['3759', '1', '5'],\n",
       " ['36425', '1', '5'],\n",
       " ['10279', '1', '5'],\n",
       " ['12184', '1', '5'],\n",
       " ['31284', '1', '4'],\n",
       " ['2824', '1', '4'],\n",
       " ['14928', '1', '5'],\n",
       " ['13944', '1', '5'],\n",
       " ['45288', '1', '5'],\n",
       " ['15224', '1', '5'],\n",
       " ['38561', '1', '5'],\n",
       " ['9018', '1', '3'],\n",
       " ['45111', '1', '5'],\n",
       " ['25286', '1', '5'],\n",
       " ['26107', '1', '3'],\n",
       " ['45931', '1', '4'],\n",
       " ['33679', '1', '4'],\n",
       " ['30936', '1', '4'],\n",
       " ['9251', '1', '5'],\n",
       " ['16621', '1', '4'],\n",
       " ['3464', '1', '5'],\n",
       " ['13490', '1', '4'],\n",
       " ['1792', '1', '4'],\n",
       " ['34132', '1', '5'],\n",
       " ['34950', '1', '5'],\n",
       " ['12887', '1', '4'],\n",
       " ['33259', '1', '5'],\n",
       " ['1309', '1', '5'],\n",
       " ['8574', '1', '4'],\n",
       " ['4399', '1', '4'],\n",
       " ['22794', '1', '5'],\n",
       " ['12720', '1', '5'],\n",
       " ['28777', '1', '5'],\n",
       " ['31981', '1', '5'],\n",
       " ['4081', '1', '4'],\n",
       " ['45766', '1', '5'],\n",
       " ['8010', '1', '4'],\n",
       " ['17984', '1', '5'],\n",
       " ['41936', '1', '3'],\n",
       " ['15911', '1', '5'],\n",
       " ['13564', '1', '4'],\n",
       " ['45701', '1', '5'],\n",
       " ['18404', '1', '4'],\n",
       " ['3997', '1', '4'],\n",
       " ['31962', '1', '5'],\n",
       " ['21633', '1', '3'],\n",
       " ['850', '1', '5'],\n",
       " ['13694', '1', '4'],\n",
       " ['3061', '1', '4'],\n",
       " ['30889', '1', '5'],\n",
       " ['40675', '1', '4'],\n",
       " ['29431', '1', '5'],\n",
       " ['50153', '1', '4'],\n",
       " ['1455', '1', '3'],\n",
       " ['44570', '1', '4'],\n",
       " ['44425', '1', '5'],\n",
       " ['31438', '1', '3'],\n",
       " ['17529', '1', '5'],\n",
       " ['49129', '1', '4'],\n",
       " ['12998', '1', '3'],\n",
       " ['12944', '1', '5'],\n",
       " ['10433', '1', '4'],\n",
       " ['14150', '1', '5'],\n",
       " ['43028', '1', '4'],\n",
       " ['19783', '1', '3'],\n",
       " ['22864', '1', '5'],\n",
       " ['18316', '1', '5'],\n",
       " ['8539', '1', '3'],\n",
       " ['14883', '1', '5'],\n",
       " ['15586', '1', '5'],\n",
       " ['11273', '1', '5'],\n",
       " ['37967', '1', '4'],\n",
       " ['892', '1', '4'],\n",
       " ['10460', '1', '5'],\n",
       " ['44688', '1', '5'],\n",
       " ['6909', '1', '5'],\n",
       " ['30221', '1', '5'],\n",
       " ['4396', '1', '4'],\n",
       " ['21458', '1', '4'],\n",
       " ['15720', '1', '4'],\n",
       " ['18286', '1', '5'],\n",
       " ['7170', '1', '5'],\n",
       " ['43413', '1', '5'],\n",
       " ['4917', '1', '4'],\n",
       " ['1612', '1', '4'],\n",
       " ['43027', '1', '5'],\n",
       " ['45910', '1', '3'],\n",
       " ['31116', '1', '4'],\n",
       " ['47684', '1', '5'],\n",
       " ['47205', '1', '5'],\n",
       " ['15674', '1', '5'],\n",
       " ['34875', '1', '3'],\n",
       " ['49443', '1', '4'],\n",
       " ['23047', '1', '5'],\n",
       " ['52106', '1', '5'],\n",
       " ['29342', '1', '3'],\n",
       " ['8909', '1', '5'],\n",
       " ['32124', '1', '5'],\n",
       " ['31033', '1', '4'],\n",
       " ['17015', '1', '4'],\n",
       " ['11290', '1', '5'],\n",
       " ['16222', '1', '5'],\n",
       " ['25070', '1', '4'],\n",
       " ['28948', '1', '5'],\n",
       " ['21550', '1', '5'],\n",
       " ['3860', '1', '3'],\n",
       " ['40690', '1', '5'],\n",
       " ['14525', '1', '5'],\n",
       " ['49180', '1', '5'],\n",
       " ['42675', '1', '5'],\n",
       " ['9093', '1', '5'],\n",
       " ['19645', '1', '5'],\n",
       " ['51910', '1', '3'],\n",
       " ['28442', '1', '3'],\n",
       " ['18524', '1', '5'],\n",
       " ['13493', '1', '5'],\n",
       " ['15995', '1', '4'],\n",
       " ['20897', '1', '5'],\n",
       " ['14996', '1', '4'],\n",
       " ['7807', '1', '5'],\n",
       " ['13941', '1', '4'],\n",
       " ['49720', '1', '5'],\n",
       " ['19951', '1', '4'],\n",
       " ['36048', '1', '1'],\n",
       " ['25824', '1', '5'],\n",
       " ['1052', '1', '4'],\n",
       " ['24008', '1', '5'],\n",
       " ['26609', '1', '4'],\n",
       " ['52847', '1', '4'],\n",
       " ['13412', '1', '4'],\n",
       " ['25916', '1', '4'],\n",
       " ['1394', '1', '3'],\n",
       " ['26203', '1', '5'],\n",
       " ['12906', '1', '5'],\n",
       " ['5391', '1', '4'],\n",
       " ['6942', '1', '3'],\n",
       " ['11119', '1', '4'],\n",
       " ['28877', '1', '5'],\n",
       " ['46301', '1', '4'],\n",
       " ['21036', '1', '5'],\n",
       " ['22811', '1', '4'],\n",
       " ['42123', '1', '4'],\n",
       " ['50802', '1', '4'],\n",
       " ['976', '1', '5'],\n",
       " ['19538', '1', '4'],\n",
       " ['15640', '1', '5'],\n",
       " ['39168', '1', '5'],\n",
       " ['1046', '1', '4'],\n",
       " ['19024', '1', '4'],\n",
       " ['20970', '1', '4'],\n",
       " ['14253', '1', '5'],\n",
       " ['38974', '1', '5'],\n",
       " ['1701', '1', '4'],\n",
       " ['15620', '1', '4'],\n",
       " ['8221', '1', '5'],\n",
       " ['46651', '1', '5'],\n",
       " ['51158', '1', '4'],\n",
       " ['19484', '1', '4'],\n",
       " ['18927', '1', '5'],\n",
       " ['750', '1', '4'],\n",
       " ['18681', '1', '5'],\n",
       " ['49732', '1', '5'],\n",
       " ['1374', '1', '3'],\n",
       " ['40436', '1', '4'],\n",
       " ['25319', '1', '5'],\n",
       " ['37073', '1', '5'],\n",
       " ['32064', '1', '4'],\n",
       " ['25504', '1', '5'],\n",
       " ['38613', '1', '5'],\n",
       " ['35021', '1', '5'],\n",
       " ['26322', '1', '5'],\n",
       " ['39494', '1', '4'],\n",
       " ['38864', '1', '4'],\n",
       " ['31556', '1', '4'],\n",
       " ['12028', '1', '3'],\n",
       " ['1175', '1', '5'],\n",
       " ['42092', '1', '5'],\n",
       " ['8532', '1', '4'],\n",
       " ['45832', '1', '5'],\n",
       " ['3223', '1', '4'],\n",
       " ['35621', '1', '5'],\n",
       " ['41797', '1', '5'],\n",
       " ['20574', '1', '5'],\n",
       " ['6182', '1', '4'],\n",
       " ['22283', '1', '3'],\n",
       " ['29763', '1', '4'],\n",
       " ['6530', '1', '5'],\n",
       " ['52916', '1', '5'],\n",
       " ['43486', '1', '4'],\n",
       " ['47031', '1', '5'],\n",
       " ['11228', '1', '5'],\n",
       " ['2292', '1', '4'],\n",
       " ['34543', '1', '4'],\n",
       " ['10021', '1', '5'],\n",
       " ['31846', '1', '5'],\n",
       " ['39601', '1', '5'],\n",
       " ['41507', '1', '4'],\n",
       " ['41360', '1', '5'],\n",
       " ['12778', '1', '3'],\n",
       " ['48896', '1', '4'],\n",
       " ['24603', '1', '5'],\n",
       " ['33812', '1', '3'],\n",
       " ['19426', '1', '4'],\n",
       " ['657', '1', '3'],\n",
       " ['43082', '1', '5'],\n",
       " ['16512', '1', '5'],\n",
       " ['39235', '1', '5'],\n",
       " ['14109', '1', '5'],\n",
       " ['10954', '1', '4'],\n",
       " ['5717', '1', '4'],\n",
       " ['7455', '1', '5'],\n",
       " ['49950', '1', '4'],\n",
       " ['30466', '1', '5'],\n",
       " ['44943', '1', '5'],\n",
       " ['13553', '1', '4'],\n",
       " ['1996', '1', '5'],\n",
       " ['46203', '1', '5'],\n",
       " ['10432', '1', '5'],\n",
       " ['31518', '1', '4'],\n",
       " ['37592', '1', '5'],\n",
       " ['3838', '1', '4'],\n",
       " ['41956', '1', '5'],\n",
       " ['12780', '1', '4'],\n",
       " ['20318', '1', '4'],\n",
       " ['5341', '1', '3'],\n",
       " ['8253', '1', '2'],\n",
       " ['18914', '1', '5'],\n",
       " ['48151', '1', '5'],\n",
       " ['51839', '1', '5'],\n",
       " ['9290', '1', '5'],\n",
       " ['17467', '1', '5'],\n",
       " ['29879', '1', '5'],\n",
       " ['24774', '1', '5'],\n",
       " ['22599', '1', '5'],\n",
       " ['2419', '1', '5'],\n",
       " ['26456', '1', '5'],\n",
       " ['13353', '1', '5'],\n",
       " ['28437', '1', '5'],\n",
       " ['4453', '1', '3'],\n",
       " ['51799', '1', '4'],\n",
       " ['52323', '1', '4'],\n",
       " ['38472', '1', '3'],\n",
       " ['22167', '1', '3'],\n",
       " ['23885', '1', '5'],\n",
       " ['33107', '1', '5'],\n",
       " ['40835', '1', '4'],\n",
       " ['52200', '1', '4'],\n",
       " ['28691', '1', '4'],\n",
       " ['17532', '1', '5'],\n",
       " ['39610', '1', '5'],\n",
       " ['1127', '1', '4'],\n",
       " ['52858', '1', '4'],\n",
       " ['25923', '1', '5'],\n",
       " ['25900', '1', '5'],\n",
       " ['7733', '1', '4'],\n",
       " ['52966', '1', '4'],\n",
       " ['1299', '1', '4'],\n",
       " ['30209', '1', '5'],\n",
       " ['10005', '1', '5'],\n",
       " ['51019', '1', '5'],\n",
       " ['1043', '1', '4'],\n",
       " ['38298', '1', '5'],\n",
       " ['3487', '1', '4'],\n",
       " ['34159', '1', '4'],\n",
       " ['2051', '1', '3'],\n",
       " ['45335', '1', '5'],\n",
       " ['24219', '1', '4'],\n",
       " ['7226', '1', '5'],\n",
       " ['38897', '1', '5'],\n",
       " ['11456', '1', '3'],\n",
       " ['14115', '1', '5'],\n",
       " ['9861', '1', '5'],\n",
       " ['21278', '1', '5'],\n",
       " ['6657', '1', '5'],\n",
       " ['13352', '1', '4'],\n",
       " ['4880', '1', '5'],\n",
       " ['293', '1', '4'],\n",
       " ['26726', '1', '3'],\n",
       " ['36023', '1', '5'],\n",
       " ['50610', '1', '4'],\n",
       " ['16849', '1', '4'],\n",
       " ['31147', '1', '5'],\n",
       " ['1368', '1', '2'],\n",
       " ['36073', '1', '4'],\n",
       " ['9011', '1', '3'],\n",
       " ['15672', '1', '5'],\n",
       " ['10117', '1', '5'],\n",
       " ['22944', '1', '5'],\n",
       " ['34434', '1', '5'],\n",
       " ['16101', '1', '5'],\n",
       " ['37205', '1', '4'],\n",
       " ['14581', '1', '5'],\n",
       " ['19568', '1', '5'],\n",
       " ['255', '1', '4'],\n",
       " ['26508', '1', '4'],\n",
       " ['7348', '1', '5'],\n",
       " ['8012', '1', '4'],\n",
       " ['51400', '1', '5'],\n",
       " ['13891', '1', '4'],\n",
       " ['51700', '1', '5'],\n",
       " ['12107', '1', '5'],\n",
       " ['26762', '1', '4'],\n",
       " ['858', '1', '4'],\n",
       " ['21463', '1', '3'],\n",
       " ['46371', '1', '4'],\n",
       " ['32999', '1', '5'],\n",
       " ['18179', '1', '5'],\n",
       " ['16434', '1', '5'],\n",
       " ['8078', '1', '4'],\n",
       " ['36800', '1', '5'],\n",
       " ['38308', '1', '5'],\n",
       " ['19957', '1', '5'],\n",
       " ['23214', '1', '4'],\n",
       " ['8018', '1', '5'],\n",
       " ['5304', '1', '5'],\n",
       " ['1247', '1', '5'],\n",
       " ['27815', '1', '5'],\n",
       " ['44035', '1', '5'],\n",
       " ['10713', '1', '5'],\n",
       " ['36006', '1', '4'],\n",
       " ['36264', '1', '4'],\n",
       " ['50144', '1', '5'],\n",
       " ['33365', '1', '5'],\n",
       " ['20336', '1', '4'],\n",
       " ['51579', '1', '5'],\n",
       " ['5239', '1', '5'],\n",
       " ['40128', '1', '4'],\n",
       " ['12995', '1', '5'],\n",
       " ['28550', '1', '5'],\n",
       " ['11350', '1', '5'],\n",
       " ['15313', '1', '5'],\n",
       " ['46048', '1', '4'],\n",
       " ['5501', '1', '3'],\n",
       " ['4845', '1', '4'],\n",
       " ['14853', '1', '4'],\n",
       " ['25921', '1', '3'],\n",
       " ['42215', '1', '4'],\n",
       " ['2019', '1', '5'],\n",
       " ['39065', '1', '5'],\n",
       " ['49464', '1', '5'],\n",
       " ['49542', '1', '5'],\n",
       " ['8205', '1', '5'],\n",
       " ['42387', '1', '5'],\n",
       " ['28800', '1', '5'],\n",
       " ['44833', '1', '5'],\n",
       " ['23332', '1', '5'],\n",
       " ['48040', '1', '5'],\n",
       " ['49752', '1', '5'],\n",
       " ['48775', '1', '5'],\n",
       " ['35468', '1', '4'],\n",
       " ['7675', '1', '4'],\n",
       " ['24487', '1', '3'],\n",
       " ['51223', '1', '5'],\n",
       " ['26196', '1', '4'],\n",
       " ['39571', '1', '5'],\n",
       " ['13966', '1', '5'],\n",
       " ['26420', '1', '5'],\n",
       " ['47569', '1', '5'],\n",
       " ['726', '1', '4'],\n",
       " ['51357', '1', '5'],\n",
       " ['19338', '1', '5'],\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1793688 train ratings, 448422 test ratings\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "def train_test_split(raw_ratings, ratio=0.8):\n",
    "    random.Random(0).shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "    cutoff = int(.8 * len(raw_ratings))\n",
    "    train_ratings = raw_ratings[:cutoff]\n",
    "    test_ratings = raw_ratings[cutoff:]\n",
    "    return train_ratings, test_ratings\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(raw_ratings)\n",
    "print(\"{} train ratings, {} test ratings\".format(len(train_ratings), len(test_ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the input to map goodreads IDs to new internal IDs\n",
    "# The new internal IDs will be created by the defaultdict on insertion\n",
    "books_to_internal_user_ids = defaultdict(lambda: len(books_to_internal_user_ids))\n",
    "books_to_internal_item_ids = defaultdict(lambda: len(books_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = books_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = books_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])\n",
    "n_users = len(books_to_internal_user_ids)\n",
    "n_items = len(books_to_internal_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method converts a list of (user, item, rating, time) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "shape=(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(train_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n",
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "item_features=item_indicator_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cf_model.predict(user_features=user_indicator_features,\n",
    "                            item_features=item_indicator_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4599879, 3.4518158, 3.1528764, ..., 3.1779628, 3.2775123,\n",
       "        3.280781 ],\n",
       "       [4.5791855, 4.2004714, 4.039655 , ..., 3.7314146, 3.9133234,\n",
       "        3.8777552],\n",
       "       [2.8395836, 2.945003 , 2.9636202, ..., 2.965521 , 3.064954 ,\n",
       "        3.1529503],\n",
       "       ...,\n",
       "       [2.9269216, 2.9726179, 3.0228062, ..., 2.9429085, 3.0586312,\n",
       "        3.204864 ],\n",
       "       [2.926758 , 2.9701684, 3.0223927, ..., 2.9416153, 3.0567262,\n",
       "        3.2042649],\n",
       "       [2.92774  , 2.969245 , 3.029328 , ..., 2.9419734, 3.0570192,\n",
       "        3.2037506]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets of train/test interactions that are only ratings >= 4.0\n",
    "sparse_train_ratings_4plus = sparse_train_ratings.multiply(sparse_train_ratings >= 4.0)\n",
    "sparse_test_ratings_4plus = sparse_test_ratings.multiply(sparse_test_ratings >= 4.0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method consumes item ranks for each user and prints out recall@10 train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    train_precision_at_10 = tensorrec.eval.precision_at_k(\n",
    "        test_interactions=sparse_train_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_precision_at_10 = tensorrec.eval.precision_at_k(\n",
    "        test_interactions=sparse_test_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    train_ndcg_at_10 = tensorrec.eval.ndcg_at_k(\n",
    "        test_interactions=sparse_train_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_ndcg_at_10 = tensorrec.eval.ndcg_at_k(\n",
    "        test_interactions=sparse_test_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Recall at 10: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "    print(\"Precision at 10: Train: {:.4f} Test: {:.4f}\".format(train_precision_at_10,\n",
    "                                                            test_precision_at_10))\n",
    "    print(\"NDCG at 10: Train: {:.4f} Test: {:.4f}\".format(train_ndcg_at_10,\n",
    "                                                            test_ndcg_at_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization collaborative filter:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 10: Train: 0.0678 Test: 0.0585\n",
      "Precision at 10: Train: 0.1239 Test: 0.0310\n",
      "NDCG at 10: Train: 0.1306 Test: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Matrix factorization collaborative filter:\n",
    "Recall at 10: Train: 0.0221 Test: 0.0213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training collaborative filter with WMRB loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMRB matrix factorization collaborative filter:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 10: Train: 0.1580 Test: 0.1306\n",
      "Precision at 10: Train: 0.3055 Test: 0.0710\n",
      "NDCG at 10: Train: 0.2877 Test: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    }
   ],
   "source": [
    "# Let's try a new loss function: WMRB\n",
    "\n",
    "\n",
    "###\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items * .01))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training collaborative filter with WMRB loss\n",
    "WMRB matrix factorization collaborative filter:\n",
    "Recall at 10: Train: 0.0585 Test: 0.0552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - намалих си данните и така ми се увеличи резултата??? нещо не е наред, да разгледам \n",
    "#малко по-подробно функциите и евентуално да направя cross-evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based filtering with book embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_book_embeddings(infile, outfile, n_books=N_BOOKS, emd_dim=EMBEDDING_DIMENTIONS):\n",
    "    \"\"\"\n",
    "    Create a file with the embeddings that are only of the book nodes. \n",
    "    \"\"\"\n",
    "    nodes_emb = pd.read_csv(infile, sep=' ', header=None, index_col=0, skiprows=1)\n",
    "    print(len(nodes_emb))\n",
    "    print(nodes_emb.head())\n",
    "    nodes_emb_sorted = nodes_emb.sort_index()\n",
    "    nodes_emb_books=nodes_emb_sorted.head(n_books)\n",
    "    print(len(nodes_emb_books))\n",
    "    print(nodes_emb_books.head())\n",
    "    nodes_emb_books.to_csv(outfile, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13380\n",
      "             1         2         3         4         5         6         7    \\\n",
      "0                                                                              \n",
      "130574  0.343741  1.144867  0.520509  0.184540  0.697892  0.377195  0.899975   \n",
      "111743  0.144308  0.509947  0.236566  0.082273  0.303050  0.161530  0.403527   \n",
      "108717  0.138341  0.482995  0.226414  0.080604  0.291387  0.153742  0.382147   \n",
      "111557  0.119607  0.413404  0.194941  0.071990  0.244740  0.135814  0.327056   \n",
      "111305  0.119086  0.406895  0.185425  0.069152  0.246882  0.133862  0.321073   \n",
      "\n",
      "             8         9         10   ...       119       120       121  \\\n",
      "0                                     ...                                 \n",
      "130574  0.387989  0.777880 -0.814670  ...  0.141990  1.411326 -1.217900   \n",
      "111743  0.170486  0.344542 -0.360932  ...  0.065931  0.627696 -0.539220   \n",
      "108717  0.157744  0.323199 -0.341189  ...  0.056345  0.594580 -0.512271   \n",
      "111557  0.140245  0.278803 -0.293099  ...  0.052401  0.508873 -0.436090   \n",
      "111305  0.130187  0.266117 -0.279625  ...  0.059105  0.502806 -0.421870   \n",
      "\n",
      "             122       123       124       125       126       127       128  \n",
      "0                                                                             \n",
      "130574  0.145937 -0.880694 -0.209896 -0.166879 -0.244107  0.421434  0.021024  \n",
      "111743  0.064901 -0.385541 -0.095069 -0.070610 -0.106066  0.190679  0.013073  \n",
      "108717  0.055379 -0.363476 -0.094395 -0.067814 -0.105084  0.182609  0.014018  \n",
      "111557  0.054625 -0.318745 -0.075776 -0.054293 -0.092537  0.154435  0.012244  \n",
      "111305  0.058911 -0.314348 -0.074794 -0.063819 -0.088634  0.154354  0.015817  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "2000\n",
      "        1         2         3         4         5         6         7    \\\n",
      "0                                                                         \n",
      "1 -0.005412 -0.009758 -0.001974 -0.001245 -0.005370 -0.007581 -0.010505   \n",
      "2  0.004807  0.006320  0.004236 -0.001680  0.000761 -0.000484  0.000115   \n",
      "3 -0.005753 -0.016819 -0.007610 -0.003173 -0.013899 -0.008617 -0.016474   \n",
      "5  0.000944 -0.000083 -0.001413 -0.002312 -0.004882 -0.001933 -0.004694   \n",
      "6  0.003615  0.003535  0.003176 -0.003561  0.000043  0.003531 -0.000639   \n",
      "\n",
      "        8         9         10   ...       119       120       121       122  \\\n",
      "0                                ...                                           \n",
      "1 -0.004591 -0.008552  0.010850  ... -0.000926 -0.013913  0.011258  0.001815   \n",
      "2 -0.001093 -0.000153 -0.002557  ... -0.002360  0.006336 -0.006319  0.000603   \n",
      "3 -0.002846 -0.011146  0.009794  ... -0.004271 -0.023070  0.016920 -0.001107   \n",
      "5 -0.000444 -0.002381  0.002736  ... -0.001447  0.000013  0.001518 -0.000564   \n",
      "6  0.003457  0.002574 -0.004269  ...  0.002350  0.007062 -0.004668 -0.001814   \n",
      "\n",
      "        123       124       125       126       127       128  \n",
      "0                                                              \n",
      "1  0.005929  0.002649  0.001986  0.001555 -0.000508  0.002407  \n",
      "2 -0.004650 -0.002330 -0.004314 -0.002294  0.005619 -0.003281  \n",
      "3  0.015458  0.001389  0.005143  0.005356 -0.006792 -0.000260  \n",
      "5  0.001440  0.001668 -0.000605  0.001455  0.000007  0.002271  \n",
      "6 -0.001687  0.002416  0.000795 -0.004800  0.000493  0.000343  \n",
      "\n",
      "[5 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "INFILE = \"emb/book_tags_100_directed_raw.emd\"\n",
    "OUTFILE = \"emb/book_tags_100_directed.emd\"\n",
    "create_book_embeddings(INFILE, OUTFILE)\n",
    "#OUTFILE = \"emb/tags_and_genres_old.emd\"\n",
    "\n",
    "#'tag_count_reduced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading book embeddings... \n"
     ]
    }
   ],
   "source": [
    "# To improve the recommendations, lets read in the movie genres\n",
    "print('Loading book embeddings... ')\n",
    "with open(OUTFILE, 'r') as emb_file:\n",
    "    emb_file_reader = csv.reader(emb_file)\n",
    "    raw_tags_embeddings = list(emb_file_reader)\n",
    "# raw_movie_metadata_header = raw_movie_metadata.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading book embeddings...\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "print('Loading book embeddings...')\n",
    "b_feat = pd.read_csv(OUTFILE, header=None)\n",
    "books_features = sparse.coo_matrix(b_feat)\n",
    "n_features = b_feat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005412</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>-0.005370</td>\n",
       "      <td>-0.007581</td>\n",
       "      <td>-0.010505</td>\n",
       "      <td>-0.004591</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.013913</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>0.002407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>-0.001680</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>-0.006319</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>-0.004314</td>\n",
       "      <td>-0.002294</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.016819</td>\n",
       "      <td>-0.007610</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>-0.016474</td>\n",
       "      <td>-0.002846</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004271</td>\n",
       "      <td>-0.023070</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.006792</td>\n",
       "      <td>-0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000944</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>-0.002312</td>\n",
       "      <td>-0.004882</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>-0.004668</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.002474</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.004824</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>-0.003351</td>\n",
       "      <td>-0.005582</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>-0.013355</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>-0.003358</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.004030</td>\n",
       "      <td>-0.004153</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.004588</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002651</td>\n",
       "      <td>-0.003164</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.002431</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>-0.001567</td>\n",
       "      <td>-0.004501</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.003056</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.004515</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.006524</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>-0.011290</td>\n",
       "      <td>-0.005798</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.005412 -0.009758 -0.001974 -0.001245 -0.005370 -0.007581 -0.010505   \n",
       "1     0.004807  0.006320  0.004236 -0.001680  0.000761 -0.000484  0.000115   \n",
       "2    -0.005753 -0.016819 -0.007610 -0.003173 -0.013899 -0.008617 -0.016474   \n",
       "3     0.000944 -0.000083 -0.001413 -0.002312 -0.004882 -0.001933 -0.004694   \n",
       "4     0.003615  0.003535  0.003176 -0.003561  0.000043  0.003531 -0.000639   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995 -0.002474 -0.010803 -0.004824 -0.003697 -0.003351 -0.005582 -0.005707   \n",
       "1996 -0.004030 -0.004153  0.000781  0.001401 -0.003253 -0.000085 -0.004588   \n",
       "1997 -0.004043 -0.002431 -0.001540  0.002563 -0.002461 -0.001567 -0.004501   \n",
       "1998 -0.004515 -0.004896  0.001805 -0.000948  0.000606  0.000751 -0.000890   \n",
       "1999  0.000934 -0.011290 -0.005798  0.001871 -0.003100 -0.003008 -0.003653   \n",
       "\n",
       "           7         8         9    ...       118       119       120  \\\n",
       "0    -0.004591 -0.008552  0.010850  ... -0.000926 -0.013913  0.011258   \n",
       "1    -0.001093 -0.000153 -0.002557  ... -0.002360  0.006336 -0.006319   \n",
       "2    -0.002846 -0.011146  0.009794  ... -0.004271 -0.023070  0.016920   \n",
       "3    -0.000444 -0.002381  0.002736  ... -0.001447  0.000013  0.001518   \n",
       "4     0.003457  0.002574 -0.004269  ...  0.002350  0.007062 -0.004668   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995 -0.005117 -0.003806  0.008666  ...  0.001354 -0.013355  0.008643   \n",
       "1996  0.003523  0.002980  0.000581  ... -0.002651 -0.003164 -0.000266   \n",
       "1997 -0.000371  0.000387  0.001208  ... -0.003474 -0.003056  0.003739   \n",
       "1998 -0.003430 -0.006524 -0.000418  ...  0.000371 -0.003519  0.002104   \n",
       "1999 -0.002074 -0.007138  0.007078  ...  0.001236 -0.013818  0.012689   \n",
       "\n",
       "           121       122       123       124       125       126       127  \n",
       "0     0.001815  0.005929  0.002649  0.001986  0.001555 -0.000508  0.002407  \n",
       "1     0.000603 -0.004650 -0.002330 -0.004314 -0.002294  0.005619 -0.003281  \n",
       "2    -0.001107  0.015458  0.001389  0.005143  0.005356 -0.006792 -0.000260  \n",
       "3    -0.000564  0.001440  0.001668 -0.000605  0.001455  0.000007  0.002271  \n",
       "4    -0.001814 -0.001687  0.002416  0.000795 -0.004800  0.000493  0.000343  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995 -0.003358  0.006447  0.002162 -0.000213  0.003503 -0.000205  0.002113  \n",
       "1996  0.000308 -0.001204  0.002242  0.002648  0.000049  0.002612  0.000050  \n",
       "1997 -0.002558 -0.002405 -0.000657 -0.002760 -0.003646  0.000878 -0.000970  \n",
       "1998  0.002492  0.005905  0.000733  0.002440  0.003454 -0.000438  0.001823  \n",
       "1999 -0.004369  0.008954  0.002060  0.002483 -0.000177 -0.005850  0.003469  \n",
       "\n",
       "[2000 rows x 128 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 128)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005412</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>-0.005370</td>\n",
       "      <td>-0.007581</td>\n",
       "      <td>-0.010505</td>\n",
       "      <td>-0.004591</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.013913</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>0.002407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>-0.001680</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>-0.006319</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>-0.004314</td>\n",
       "      <td>-0.002294</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.016819</td>\n",
       "      <td>-0.007610</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>-0.016474</td>\n",
       "      <td>-0.002846</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004271</td>\n",
       "      <td>-0.023070</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>-0.006792</td>\n",
       "      <td>-0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000944</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>-0.002312</td>\n",
       "      <td>-0.004882</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>-0.003561</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>-0.004668</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.005412 -0.009758 -0.001974 -0.001245 -0.005370 -0.007581 -0.010505   \n",
       "1  0.004807  0.006320  0.004236 -0.001680  0.000761 -0.000484  0.000115   \n",
       "2 -0.005753 -0.016819 -0.007610 -0.003173 -0.013899 -0.008617 -0.016474   \n",
       "3  0.000944 -0.000083 -0.001413 -0.002312 -0.004882 -0.001933 -0.004694   \n",
       "4  0.003615  0.003535  0.003176 -0.003561  0.000043  0.003531 -0.000639   \n",
       "\n",
       "        7         8         9    ...       118       119       120       121  \\\n",
       "0 -0.004591 -0.008552  0.010850  ... -0.000926 -0.013913  0.011258  0.001815   \n",
       "1 -0.001093 -0.000153 -0.002557  ... -0.002360  0.006336 -0.006319  0.000603   \n",
       "2 -0.002846 -0.011146  0.009794  ... -0.004271 -0.023070  0.016920 -0.001107   \n",
       "3 -0.000444 -0.002381  0.002736  ... -0.001447  0.000013  0.001518 -0.000564   \n",
       "4  0.003457  0.002574 -0.004269  ...  0.002350  0.007062 -0.004668 -0.001814   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0  0.005929  0.002649  0.001986  0.001555 -0.000508  0.002407  \n",
       "1 -0.004650 -0.002330 -0.004314 -0.002294  0.005619 -0.003281  \n",
       "2  0.015458  0.001389  0.005143  0.005356 -0.006792 -0.000260  \n",
       "3  0.001440  0.001668 -0.000605  0.001455  0.000007  0.002271  \n",
       "4 -0.001687  0.002416  0.000795 -0.004800  0.000493  0.000343  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the genres as item features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "    item_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph(),\n",
    "     loss_graph=tensorrec.loss_graphs.WMRBLossGraph(),\n",
    "#     prediction_graph=CosineSimilarityPredictionGraph,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                  user_features=user_indicator_features,\n",
    "                  item_features=books_features,\n",
    "                 n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommender:\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_indicator_features,\n",
    "                                             item_features=books_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52943, 2000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb/book_tags_100_directed.emd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 10: Train: 0.0066 Test: 0.0066\n",
      "Precision at 10: Train: 0.0164 Test: 0.0044\n",
      "NDCG at 10: Train: 0.0099 Test: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndcg = dcg/idcg\n"
     ]
    }
   ],
   "source": [
    "print(OUTFILE)\n",
    "check_results(predicted_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-9158b6cd5835>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-9158b6cd5835>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    emb/book_tags_class_stacked_100_dim.emb - random seed 0\u001b[0m\n\u001b[1;37m                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emb/book_tags_class_stacked_100_dim.emb - random seed 0\n",
    "Recall at 10: Train: 0.0677 Test: 0.0389\n",
    "Precision at 10: Train: 0.1390 Test: 0.0211\n",
    "NDCG at 10: Train: 0.1126 Test: 0.0277"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/book_tags_100_dim.emb - with random seed 0 \n",
    "Recall at 10: Train: 0.0800 Test: 0.0424\n",
    "Precision at 10: Train: 0.1689 Test: 0.0237\n",
    "NDCG at 10: Train: 0.1500 Test: 0.0337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-df568698a3b4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-df568698a3b4>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Recall at 10: Train: 0.0565 Test: 0.0236\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emb/book_tags_100_dim.emb\n",
    "Recall at 10: Train: 0.0565 Test: 0.0236\n",
    "Precision at 10: Train: 0.1204 Test: 0.0131\n",
    "NDCG at 10: Train: 0.0961 Test: 0.0161\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-253a8eacffe3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-253a8eacffe3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Recall at 10: Train: 0.0748 Test: 0.0329\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emb/book_tags_100_dim.emb\n",
    "Recall at 10: Train: 0.0748 Test: 0.0329\n",
    "Precision at 10: Train: 0.1488 Test: 0.0171\n",
    "NDCG at 10: Train: 0.1213 Test: 0.0207\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-660a49373f6d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-660a49373f6d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Recall at 10: Train: 0.1018 Test: 0.0486\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emb/book_tag_class_new.emb\n",
    "Recall at 10: Train: 0.1018 Test: 0.0486\n",
    "Precision at 10: Train: 0.2041 Test: 0.0256\n",
    "NDCG at 10: Train: 0.1960 Test: 0.0363"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/book_tags.emb\n",
    "Recall at 10: Train: 0.0808 Test: 0.0372\n",
    "Precision at 10: Train: 0.1710 Test: 0.0214\n",
    "NDCG at 10: Train: 0.1553 Test: 0.0289\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/book_tag_links_glove_w_d_128\n",
    "Recall at 10: Train: 0.0623 Test: 0.0617\n",
    "Precision at 10: Train: 0.1326 Test: 0.0352\n",
    "NDCG at 10: Train: 0.1428 Test: 0.0597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-633b828e7263>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-633b828e7263>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Recall at 10: Train: 0.0506 Test: 0.0509\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "emb/tags_and_genres_d_w_128.emd\n",
    "Recall at 10: Train: 0.0506 Test: 0.0509\n",
    "Precision at 10: Train: 0.1077 Test: 0.0285\n",
    "NDCG at 10: Train: 0.1090 Test: 0.0466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emb/tags_and_genres_old.emd\n",
    "Recall at 10: Train: 0.0102 Test: 0.0104\n",
    "Precision at 10: Train: 0.0230 Test: 0.0061\n",
    "NDCG at 10: Train: 0.0248 Test: 0.0102\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/tags_and_genres_old.emd\n",
    "Recall at 10: Train: 0.0195 Test: 0.0196\n",
    "Precision at 10: Train: 0.0486 Test: 0.0127\n",
    "NDCG at 10: Train: 0.0294 Test: 0.0117\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/tags_and_genres_d_w.emd\n",
    "C:\\Users\\melania\\Anaconda3\\envs\\rec-sys-test\\lib\\site-packages\\tensorrec\\eval.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
    "  ndcg = dcg/idcg\n",
    "Recall at 10: Train: 0.0195 Test: 0.0196\n",
    "Precision at 10: Train: 0.0486 Test: 0.0127\n",
    "NDCG at 10: Train: 0.0294 Test: 0.0117\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb/tags_and_genres_d_w.emd - not weighted, directed \n",
    "Recall at 10: Train: 0.0237 Test: 0.0233\n",
    "Precision at 10: Train: 0.0494 Test: 0.0130\n",
    "NDCG at 10: Train: 0.0551 Test: 0.0227\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"emb/tags_and_genres_d_10.emd\" - not weighted\n",
    "Results with tags, genres and genre classes: \n",
    "Recall at 10: Train: 0.0160 Test: 0.0151\n",
    "Precision at 10: Train: 0.0362 Test: 0.0093\n",
    "NDCG at 10: Train: 0.0328 Test: 0.0125\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results with tags and ontology: \n",
    "Recall at 10: Train: 0.0463 Test: 0.0462\n",
    "Precision at 10: Train: 0.1025 Test: 0.0272\n",
    "NDCG at 10: Train: 0.0782 Test: 0.0322"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based filtering with book metadata\n",
    "\n",
    "TODO: Content-based filtering also should be one function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading books metadata\n"
     ]
    }
   ],
   "source": [
    "# To improve the recommendations, lets read in the movie genres\n",
    "#TODO: Do I need this? \n",
    "print('Loading books metadata')\n",
    "with open('book_feat_reduced_new.csv', 'r') as metadata_file:\n",
    "    metadata_file_reader = csv.reader(metadata_file)\n",
    "    raw_metadata = list(metadata_file_reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "b_feat = pd.read_csv('book_feat_reduced_new.csv', header=None)\n",
    "books_features = sparse.coo_matrix(b_feat)\n",
    "n_features = b_feat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training content-based recommender\n"
     ]
    }
   ],
   "source": [
    "# Fit a content-based model using the genres as item features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_features,\n",
    "    item_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph(),\n",
    "     loss_graph=tensorrec.loss_graphs.WMRBLossGraph()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melania\\Anaconda3\\envs\\recommendation-systems\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\melania\\Anaconda3\\envs\\recommendation-systems\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "content_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                  user_features=user_indicator_features,\n",
    "                  item_features=books_features,\n",
    "                 n_sampled_items=int(n_items * .01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-based recommender:\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_indicator_features,\n",
    "                                             item_features=books_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 10: Train: 0.0314 Test: 0.0308\n"
     ]
    }
   ],
   "source": [
    "check_results(predicted_ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
